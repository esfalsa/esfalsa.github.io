import{S as q,i as z,s as D,C as G,w as F,x as K,y as L,z as Q,A as V,f as U,t as Y,B as Z,M as W,l as w,r as p,a as B,m as y,n as b,u,h as o,c as C,p as k,b as _,a2 as n,E as ee}from"../../../../../chunks/index-042c205f.js";import{P as te}from"../../../../../chunks/_post-53d9098c.js";import"../../../../../chunks/link-4f7a5115.js";function ae(v){let e,r,l,d,a,i,s,$,c,j,E,A,m,S,f,M,P,g,T,N;return{c(){e=w("p"),r=p("It\u2019s been another few days and in that time I\u2019ve made some more progress with my region archiver script. My code actually works now!"),l=B(),d=w("p"),a=p("I\u2019ve achieved a pretty sweet performance improvement too, cutting the time to parse a daily dump from around 30 seconds to around 5. The secret trick? My internet speeds magically improved, and I have no idea why. Apparently, I forgot that I was downloading an archived data dump with my SAX parsing script, and that was the limiting factor rather than my parsing logic."),i=B(),s=w("p"),$=p("That doesn\u2019t mean my parsing logic is good, though. It\u2019s true that the script right now mostly works, but I still need to test the flag and banner downloads \u2014 NationStates just came back online after "),c=w("a"),j=p("going down for the past few days"),E=p(". A bigger problem is that I\u2019m also generating a dump of all archived data by loading the entire dump into memory, updating it, and then dumping it back into its file. It somehow works, but doesn\u2019t feel sustainable. I\u2019m leaning towards dropping the dump entirely, since if I ever do need it I could probably just read and concactenate each individual region file, but we\u2019ll see."),A=B(),m=w("p"),S=p("After some light testing, I\u2019m also beginning to think a simple frontend may be worth it after all. My original plan was just to serve the data for each region as static JSON files through GitHub pages, but build times in the ballpark of a minute (with "),f=w("a"),M=p("Astro"),P=p(", i.e., using "),g=w("a"),T=p("Vite"),N=p(" under the hood) mean it might not be so bad after all."),this.h()},l(t){e=y(t,"P",{});var h=b(e);r=u(h,"It\u2019s been another few days and in that time I\u2019ve made some more progress with my region archiver script. My code actually works now!"),h.forEach(o),l=C(t),d=y(t,"P",{});var H=b(d);a=u(H,"I\u2019ve achieved a pretty sweet performance improvement too, cutting the time to parse a daily dump from around 30 seconds to around 5. The secret trick? My internet speeds magically improved, and I have no idea why. Apparently, I forgot that I was downloading an archived data dump with my SAX parsing script, and that was the limiting factor rather than my parsing logic."),H.forEach(o),i=C(t),s=y(t,"P",{});var x=b(s);$=u(x,"That doesn\u2019t mean my parsing logic is good, though. It\u2019s true that the script right now mostly works, but I still need to test the flag and banner downloads \u2014 NationStates just came back online after "),c=y(x,"A",{href:!0,rel:!0});var J=b(c);j=u(J,"going down for the past few days"),J.forEach(o),E=u(x,". A bigger problem is that I\u2019m also generating a dump of all archived data by loading the entire dump into memory, updating it, and then dumping it back into its file. It somehow works, but doesn\u2019t feel sustainable. I\u2019m leaning towards dropping the dump entirely, since if I ever do need it I could probably just read and concactenate each individual region file, but we\u2019ll see."),x.forEach(o),A=C(t),m=y(t,"P",{});var I=b(m);S=u(I,"After some light testing, I\u2019m also beginning to think a simple frontend may be worth it after all. My original plan was just to serve the data for each region as static JSON files through GitHub pages, but build times in the ballpark of a minute (with "),f=y(I,"A",{href:!0,rel:!0});var O=b(f);M=u(O,"Astro"),O.forEach(o),P=u(I,", i.e., using "),g=y(I,"A",{href:!0,rel:!0});var R=b(g);T=u(R,"Vite"),R.forEach(o),N=u(I," under the hood) mean it might not be so bad after all."),I.forEach(o),this.h()},h(){k(c,"href","https://www.nationstates.net/page=news/2022/12/27/index.html"),k(c,"rel","nofollow"),k(f,"href","https://astro.build/"),k(f,"rel","nofollow"),k(g,"href","https://vitejs.dev/"),k(g,"rel","nofollow")},m(t,h){_(t,e,h),n(e,r),_(t,l,h),_(t,d,h),n(d,a),_(t,i,h),_(t,s,h),n(s,$),n(s,c),n(c,j),n(s,E),_(t,A,h),_(t,m,h),n(m,S),n(m,f),n(f,M),n(m,P),n(m,g),n(g,T),n(m,N)},p:ee,d(t){t&&o(e),t&&o(l),t&&o(d),t&&o(i),t&&o(s),t&&o(A),t&&o(m)}}}function oe(v){let e,r;const l=[v[0],X];let d={$$slots:{default:[ae]},$$scope:{ctx:v}};for(let a=0;a<l.length;a+=1)d=G(d,l[a]);return e=new te({props:d}),{c(){F(e.$$.fragment)},l(a){K(e.$$.fragment,a)},m(a,i){L(e,a,i),r=!0},p(a,[i]){const s=i&1?Q(l,[i&1&&V(a[0]),i&0&&V(X)]):{};i&2&&(s.$$scope={dirty:i,ctx:a}),e.$set(s)},i(a){r||(U(e.$$.fragment,a),r=!0)},o(a){Y(e.$$.fragment,a),r=!1},d(a){Z(e,a)}}}const X={title:"Region Archiver DevBlog: Well\u2026 It\u2019s Working",datetime:"2022-12-27T22:19:30-0800"};function ne(v,e,r){return v.$$set=l=>{r(0,e=G(G({},e),W(l)))},e=W(e),[e]}class le extends q{constructor(e){super(),z(this,e,ne,oe,D,{})}}export{le as default,X as metadata};
