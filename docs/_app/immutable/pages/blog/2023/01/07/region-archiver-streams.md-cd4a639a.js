import{S as j,i as E,s as B,C as x,w as z,x as D,y as O,z as C,A,f as N,t as R,B as U,M as P,l as f,r as m,a as k,m as c,n as w,u as y,h as s,c as _,b as d,a2 as I,E as M}from"../../../../../chunks/index-042c205f.js";import{P as W}from"../../../../../chunks/_post-53d9098c.js";import"../../../../../chunks/link-4f7a5115.js";function F(h){let e,o,i,r,a,n,u,v,g,p,b;return{c(){e=f("p"),o=m("It\u2019s a little weird to think that the last time I posted, I was talking about how my code was actually working. Unfortunately, I spoke a little too soon; once I linked it up with actually pulling flags from NationStates, it definitely was not working. This DevBlog won\u2019t be so much about reporting progress as reporting future plans, because progress since then has been difficult amid debugging and real-life scheduling."),i=k(),r=f("p"),a=m("One of the biggest flaws in the parsing logic I originally wrote was that it was events-driven. It could get through the daily dump itself in a matter of seconds, but would then have thousands of rate-limited flag and banner requests queued up, at least on the first run. I wasn\u2019t getting any errors, but things weren\u2019t happening in the order I was expecting and it seemed like some requests were being silently dropped. Although I tried to debug those issues for a bit, eventually I just gave up and decided to start working on a streaming parser implemention instead."),n=k(),u=f("p"),v=m("So that\u2019s where I\u2019m at now. The gist of it is that I get a stream for the daily dump download, pipe it through an unzip stream, then a parser stream that converts it into chunks of data to save, and finally to a stream writing it into files for eah region. Although I haven\u2019t copied over the parsing logic yet, I do know my stream pipeline is working at least. I\u2019m actually not entirely sure why it\u2019s working, since it\u2019s apparently able to pause and resume the download stream based on backpressure, but if that ever fails I can hopefully just save the daily dump locally and create a read stream from the file."),g=k(),p=f("p"),b=m("I do still need to actually get my code working, of course. I\u2019m pretty sure I know how to write everything I have left to write, but then again, that\u2019s what I was thinking a week and a half ago and it turns out I wasn\u2019t quite correct, so we\u2019ll have to see. It would be nice to have something working before my winter break ends in a week or so, and that\u2019s not even counting the browser extension I\u2019m planning to actually use all this data.")},l(t){e=c(t,"P",{});var l=w(e);o=y(l,"It\u2019s a little weird to think that the last time I posted, I was talking about how my code was actually working. Unfortunately, I spoke a little too soon; once I linked it up with actually pulling flags from NationStates, it definitely was not working. This DevBlog won\u2019t be so much about reporting progress as reporting future plans, because progress since then has been difficult amid debugging and real-life scheduling."),l.forEach(s),i=_(t),r=c(t,"P",{});var q=w(r);a=y(q,"One of the biggest flaws in the parsing logic I originally wrote was that it was events-driven. It could get through the daily dump itself in a matter of seconds, but would then have thousands of rate-limited flag and banner requests queued up, at least on the first run. I wasn\u2019t getting any errors, but things weren\u2019t happening in the order I was expecting and it seemed like some requests were being silently dropped. Although I tried to debug those issues for a bit, eventually I just gave up and decided to start working on a streaming parser implemention instead."),q.forEach(s),n=_(t),u=c(t,"P",{});var $=w(u);v=y($,"So that\u2019s where I\u2019m at now. The gist of it is that I get a stream for the daily dump download, pipe it through an unzip stream, then a parser stream that converts it into chunks of data to save, and finally to a stream writing it into files for eah region. Although I haven\u2019t copied over the parsing logic yet, I do know my stream pipeline is working at least. I\u2019m actually not entirely sure why it\u2019s working, since it\u2019s apparently able to pause and resume the download stream based on backpressure, but if that ever fails I can hopefully just save the daily dump locally and create a read stream from the file."),$.forEach(s),g=_(t),p=c(t,"P",{});var S=w(p);b=y(S,"I do still need to actually get my code working, of course. I\u2019m pretty sure I know how to write everything I have left to write, but then again, that\u2019s what I was thinking a week and a half ago and it turns out I wasn\u2019t quite correct, so we\u2019ll have to see. It would be nice to have something working before my winter break ends in a week or so, and that\u2019s not even counting the browser extension I\u2019m planning to actually use all this data."),S.forEach(s)},m(t,l){d(t,e,l),I(e,o),d(t,i,l),d(t,r,l),I(r,a),d(t,n,l),d(t,u,l),I(u,v),d(t,g,l),d(t,p,l),I(p,b)},p:M,d(t){t&&s(e),t&&s(i),t&&s(r),t&&s(n),t&&s(u),t&&s(g),t&&s(p)}}}function G(h){let e,o;const i=[h[0],T];let r={$$slots:{default:[F]},$$scope:{ctx:h}};for(let a=0;a<i.length;a+=1)r=x(r,i[a]);return e=new W({props:r}),{c(){z(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,n){O(e,a,n),o=!0},p(a,[n]){const u=n&1?C(i,[n&1&&A(a[0]),n&0&&A(T)]):{};n&2&&(u.$$scope={dirty:n,ctx:a}),e.$set(u)},i(a){o||(N(e.$$.fragment,a),o=!0)},o(a){R(e.$$.fragment,a),o=!1},d(a){U(e,a)}}}const T={title:"Region Archiver DevBlog: If Only It Were That Simple",datetime:"2023-01-08T17:06:11.114-0800"};function H(h,e,o){return h.$$set=i=>{o(0,e=x(x({},e),P(i)))},e=P(e),[e]}class Q extends j{constructor(e){super(),E(this,e,H,G,B,{})}}export{Q as default,T as metadata};
